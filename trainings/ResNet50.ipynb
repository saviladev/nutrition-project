{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0387413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 📦 IMPORTACIONES\n",
    "# =========================================================\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# =========================================================\n",
    "# ⚙️ CONFIGURACIÓN DE GPU\n",
    "# =========================================================\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        dev_names = [tf.config.experimental.get_device_details(g).get(\"device_name\", str(g)) for g in gpus]\n",
    "        print(f\"✅ GPUs detectadas: {len(gpus)} -> {dev_names}\")\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(f\"   Logical GPUs: {len(logical_gpus)}\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"⚠️ Error al configurar GPUs:\", e)\n",
    "else:\n",
    "    print(\"⚠️ No se detectó GPU, se usará CPU\")\n",
    "\n",
    "# --- Opcional: activar mixed precision ---\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "# (si usas esto, recuerda que la última capa Dense debe ser dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2a03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 📂 CARGAR RUTAS\n",
    "# =========================================================\n",
    "\n",
    "# Rutas actualizadas para la nueva estructura\n",
    "BASE_DIR = \"images\"\n",
    "META_DIR = \"meta/meta\"\n",
    "\n",
    "# Verificar que las rutas existen\n",
    "if os.path.exists(BASE_DIR):\n",
    "    print(f\"Se encontró la ruta: {BASE_DIR} exitosamente!\")\n",
    "if os.path.exists(META_DIR):\n",
    "    print(f\"Se encontró la ruta: {META_DIR} exitosamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4fdc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 📄 LECTURA DE SPLITS (train/test)\n",
    "# =========================================================\n",
    "def load_split(filename):\n",
    "    path = os.path.join(META_DIR, filename).replace(\"\\\\\", \"/\")\n",
    "    try:\n",
    "        with open(path, \"r\") as f:\n",
    "            lines = f.read().splitlines()\n",
    "        return lines\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ Error: No se encontró el archivo {path}\")\n",
    "        return []\n",
    "\n",
    "train_files = load_split(\"train.txt\")\n",
    "test_files = load_split(\"test.txt\")\n",
    "\n",
    "print(f\"📊 Train muestras: {len(train_files)}\")\n",
    "print(f\"📊 Test muestras: {len(test_files)}\")\n",
    "\n",
    "if len(train_files) == 0 or len(test_files) == 0:\n",
    "    print(\"❌ Error: No se pudieron cargar los archivos de splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7265bbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 📊 CREAR DATAFRAMES PARA TRAIN Y TEST\n",
    "# =========================================================\n",
    "def create_dataframe(file_list, base_dir):\n",
    "    \"\"\"Crear DataFrame con rutas de imágenes y etiquetas\"\"\"\n",
    "    data = []\n",
    "    for file_path in file_list:\n",
    "        # Extraer clase del nombre del archivo (formato: clase/imagen.jpg)\n",
    "        parts = file_path.split('/')\n",
    "        if len(parts) >= 2:\n",
    "            class_name = parts[0]\n",
    "            full_path = os.path.join(base_dir, file_path).replace(\"\\\\\", \"/\") + \".jpg\"\n",
    "            data.append({\n",
    "                'filename': full_path,\n",
    "                'class': class_name\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Crear DataFrames\n",
    "train_df = create_dataframe(train_files, BASE_DIR)\n",
    "test_df = create_dataframe(test_files, BASE_DIR)\n",
    "\n",
    "print(f\"📊 Train DataFrame shape: {train_df.shape}\")\n",
    "print(f\"📊 Test DataFrame shape: {test_df.shape}\")\n",
    "print(f\"📊 Número de clases: {train_df['class'].nunique()}\")\n",
    "print(f\"📊 Clases encontradas: {sorted(train_df['class'].unique())}\")\n",
    "\n",
    "# Verificar algunas imágenes\n",
    "print(\"\\n🔍 Verificando existencia de algunas imágenes:\")\n",
    "sample_files = train_df['filename'].head().tolist()\n",
    "for file_path in sample_files:\n",
    "    exists = os.path.exists(file_path)\n",
    "    print(f\"{'✅' if exists else '❌'} {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201fbf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 🏗️ CONFIGURACIÓN DE GENERADORES DE DATOS\n",
    "# =========================================================\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Data Augmentation para entrenamiento\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Solo preprocesssing para test\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "# Crear generadores\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Calcular steps\n",
    "train_steps = train_generator.samples // BATCH_SIZE\n",
    "val_steps = val_generator.samples // BATCH_SIZE\n",
    "test_steps = test_generator.samples // BATCH_SIZE\n",
    "\n",
    "print(\"✅ Generadores creados:\")\n",
    "print(f\"📊 Train steps: {train_steps}\")\n",
    "print(f\"📊 Validation steps: {val_steps}\")\n",
    "print(f\"📊 Test steps: {test_steps}\")\n",
    "print(f\"📊 Total train images: {train_generator.samples}\")\n",
    "print(f\"📊 Total validation images: {val_generator.samples}\")\n",
    "print(f\"📊 Total test images: {test_generator.samples}\")\n",
    "print(f\"📊 Número de clases: {len(train_generator.class_indices)}\")\n",
    "\n",
    "# Verificar un batch\n",
    "try:\n",
    "    sample_batch = next(train_generator)\n",
    "    print(f\"✅ Batch de prueba: {sample_batch[0].shape}, {sample_batch[1].shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error al obtener batch de prueba: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c910828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sample_batch = next(val_generator)\n",
    "    print(f\"✅ Batch de prueba del val_generator: {sample_batch[0].shape}, {sample_batch[1].shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error al obtener batch de prueba del val_generator: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121f82ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 🏗️ CONSTRUCCIÓN DEL MODELO ResNet50\n",
    "# =========================================================\n",
    "NUM_CLASSES = len(train_generator.class_indices)\n",
    "\n",
    "# Cargar ResNet50 pre-entrenado sin la capa top\n",
    "base_model = ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(*IMG_SIZE, 3)\n",
    ")\n",
    "\n",
    "# Agregar capas personalizadas\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "predictions = layers.Dense(NUM_CLASSES, activation='softmax', name='predictions', dtype='float32')(x)\n",
    "\n",
    "# Crear el modelo completo\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "print(f\"✅ Modelo creado con {NUM_CLASSES} clases\")\n",
    "print(f\"📊 Parámetros totales: {model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba22a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 🎯 ENTRENAMIENTO POR FASES\n",
    "# =========================================================\n",
    "\n",
    "# ---- Fase 1: Entrenar solo el clasificador ----\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"🔒 FASE 1: Entrenando solo el clasificador\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Congelar ResNet50\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compilar para Fase 1\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "early_stop_fase1 = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint_fase1 = ModelCheckpoint(\n",
    "    \"best_model_fase1.h5\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Entrenar Fase 1\n",
    "print(\"🚀 Entrenando Fase 1 (solo capas densas)...\")\n",
    "history_fase1 = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stop_fase1, checkpoint_fase1],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ---- Fase 2: Fine-tuning ----\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"🔓 FASE 2: Fine-tuning (desbloqueando últimas capas)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Desbloquear las últimas capas de ResNet50\n",
    "for layer in base_model.layers[-50:]:  # últimas 50 capas\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compilar para Fase 2 con learning rate más bajo\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Callbacks para Fase 2\n",
    "early_stop_fase2 = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=7,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint_fase2 = ModelCheckpoint(\n",
    "    \"best_model_fase2.h5\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Entrenar Fase 2\n",
    "print(\"🚀 Entrenando Fase 2 (fine-tuning)...\")\n",
    "history_fase2 = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=15,\n",
    "    callbacks=[early_stop_fase2, checkpoint_fase2],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f133bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 📊 EVALUACIÓN FINAL\n",
    "# =========================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"📊 EVALUACIÓN FINAL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Evaluar en conjunto de test\n",
    "test_loss, test_accuracy = model.evaluate(\n",
    "    test_generator,\n",
    "    steps=test_steps,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"✅ Test Loss: {test_loss:.4f}\")\n",
    "print(f\"✅ Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be477bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 💾 GUARDADO DEL MODELO FINAL\n",
    "# =========================================================\n",
    "model_path = \"model_resnet50_final.h5\"\n",
    "model.save(model_path)\n",
    "print(f\"✅ Modelo final guardado en: {model_path}\")\n",
    "\n",
    "# Guardar también los pesos por separado\n",
    "weights_path = \"model_resnet50_weights.h5\"\n",
    "model.save_weights(weights_path)\n",
    "print(f\"✅ Pesos guardados en: {weights_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffde3423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 📈 VISUALIZACIÓN DE HISTORIAL (OPCIONAL)\n",
    "# =========================================================\n",
    "def plot_training_history(history1, history2, title1=\"Fase 1\", title2=\"Fase 2\"):\n",
    "    \"\"\"Función para plotear el historial de entrenamiento\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Fase 1\n",
    "    axes[0,0].plot(history1.history['accuracy'], label='Train Accuracy')\n",
    "    axes[0,0].plot(history1.history['val_accuracy'], label='Val Accuracy')\n",
    "    axes[0,0].set_title(f'{title1} - Accuracy')\n",
    "    axes[0,0].legend()\n",
    "    \n",
    "    axes[0,1].plot(history1.history['loss'], label='Train Loss')\n",
    "    axes[0,1].plot(history1.history['val_loss'], label='Val Loss')\n",
    "    axes[0,1].set_title(f'{title1} - Loss')\n",
    "    axes[0,1].legend()\n",
    "    \n",
    "    # Fase 2\n",
    "    axes[1,0].plot(history2.history['accuracy'], label='Train Accuracy')\n",
    "    axes[1,0].plot(history2.history['val_accuracy'], label='Val Accuracy')\n",
    "    axes[1,0].set_title(f'{title2} - Accuracy')\n",
    "    axes[1,0].legend()\n",
    "    \n",
    "    axes[1,1].plot(history2.history['loss'], label='Train Loss')\n",
    "    axes[1,1].plot(history2.history['val_loss'], label='Val Loss')\n",
    "    axes[1,1].set_title(f'{title2} - Loss')\n",
    "    axes[1,1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Descomentar para visualizar\n",
    "# plot_training_history(history_fase1, history_fase2)\n",
    "\n",
    "print(\"\\n🎉 ¡Entrenamiento completado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b4883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"🔍 VERIFICACIÓN DE CONFIGURACIÓN GPU\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Información básica de TensorFlow y Python\n",
    "print(f\"📦 TensorFlow version: {tf.__version__}\")\n",
    "print(f\"🐍 Python version: {sys.version}\")\n",
    "print(f\"💻 Sistema: {platform.system()} {platform.release()}\")\n",
    "\n",
    "# Verificar GPUs físicas\n",
    "physical_gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"\\n🎮 GPUs físicas detectadas: {len(physical_gpus)}\")\n",
    "\n",
    "if physical_gpus:\n",
    "    for i, gpu in enumerate(physical_gpus):\n",
    "        print(f\"   GPU {i}: {gpu}\")\n",
    "        \n",
    "        # Obtener detalles de la GPU\n",
    "        try:\n",
    "            details = tf.config.experimental.get_device_details(gpu)\n",
    "            print(f\"      Device Name: {details.get('device_name', 'N/A')}\")\n",
    "            print(f\"      Compute Capability: {details.get('compute_capability', 'N/A')}\")\n",
    "        except Exception as e:\n",
    "            print(f\"      No se pudieron obtener detalles adicionales: {e}\")\n",
    "        \n",
    "        # Configurar memory growth\n",
    "        try:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(f\"      ✅ Memory growth habilitado\")\n",
    "        except Exception as e:\n",
    "            print(f\"      ❌ Error configurando memory growth: {e}\")\n",
    "\n",
    "# Verificar GPUs lógicas\n",
    "logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "print(f\"\\n🧠 GPUs lógicas: {len(logical_gpus)}\")\n",
    "for i, gpu in enumerate(logical_gpus):\n",
    "    print(f\"   Logical GPU {i}: {gpu}\")\n",
    "\n",
    "# Test de operación en GPU\n",
    "if physical_gpus:\n",
    "    print(f\"\\n🧪 Probando operación en GPU...\")\n",
    "    try:\n",
    "        with tf.device('/GPU:0'):\n",
    "            # Test simple de multiplicación de matrices\n",
    "            a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "            b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "            c = tf.matmul(a, b)\n",
    "            \n",
    "        print(f\"✅ Operación en GPU exitosa\")\n",
    "        print(f\"   Input shape: {a.shape} x {b.shape}\")\n",
    "        print(f\"   Output shape: {c.shape}\")\n",
    "        print(f\"   Device usado: {c.device}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error en operación GPU: {e}\")\n",
    "else:\n",
    "    print(f\"\\n⚠️  No se detectaron GPUs - usando CPU\")\n",
    "\n",
    "# Información de CUDA y capacidades\n",
    "print(f\"\\n🔧 INFORMACIÓN DE SOPORTE:\")\n",
    "print(f\"   Built with CUDA: {tf.test.is_built_with_cuda()}\")\n",
    "\n",
    "# Test de disponibilidad de GPU (método más moderno)\n",
    "gpu_available = len(tf.config.list_physical_devices('GPU')) > 0\n",
    "print(f\"   GPU disponible: {gpu_available}\")\n",
    "\n",
    "# Información adicional de build\n",
    "try:\n",
    "    build_info = tf.sysconfig.get_build_info()\n",
    "    print(f\"   CUDA version: {build_info.get('cuda_version', 'N/A')}\")\n",
    "    print(f\"   cuDNN version: {build_info.get('cudnn_version', 'N/A')}\")\n",
    "except:\n",
    "    print(\"   No se pudo obtener información de build\")\n",
    "\n",
    "# Información de memoria GPU\n",
    "if physical_gpus:\n",
    "    try:\n",
    "        # Intentar obtener información de memoria\n",
    "        gpu_details = tf.config.experimental.get_memory_info('GPU:0')\n",
    "        current_mb = gpu_details['current'] / (1024**2)\n",
    "        peak_mb = gpu_details['peak'] / (1024**2)\n",
    "        print(f\"\\n💾 MEMORIA GPU:\")\n",
    "        print(f\"   Memoria actual: {current_mb:.1f} MB\")\n",
    "        print(f\"   Memoria pico: {peak_mb:.1f} MB\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n💾 Información de memoria no disponible: {e}\")\n",
    "        \n",
    "    # Test de creación de tensor grande para verificar memoria\n",
    "    try:\n",
    "        print(f\"\\n🧪 Test de memoria GPU...\")\n",
    "        with tf.device('/GPU:0'):\n",
    "            # Crear tensor de prueba (aproximadamente 100MB)\n",
    "            large_tensor = tf.random.normal((5000, 5000), dtype=tf.float32)\n",
    "            result = tf.reduce_sum(large_tensor)\n",
    "        print(f\"✅ Test de memoria exitoso: suma = {result:.2f}\")\n",
    "        del large_tensor  # Liberar memoria\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error en test de memoria: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"🎉 Verificación completada\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
